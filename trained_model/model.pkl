{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
        "import warnings\n",
        "import pickle\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "used_columns = ['Gender', 'family_history', 'Occupation', 'Mental_Health_History','Growing_Stress','Work_Interest','Social_Weakness','Mood_Swings','treatment']\n",
        "\n",
        "data = pd.read_csv(\"/content/Mental Health Dataset.csv\")\n",
        "\n",
        "data = data[used_columns]\n",
        "\n",
        "for col in data:\n",
        "  print(col, end = \" : \")\n",
        "  print(set(data[col]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0nWN4EF3jwh",
        "outputId": "fcd069ee-6240-433c-8f73-563b9fba69e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender : {'Female'}\n",
            "family_history : {'No', 'Yes', nan}\n",
            "Occupation : {'Corporate', 'Business', 'Housewife', 'Others', nan, 'Student'}\n",
            "Mental_Health_History : {'No', 'Maybe', 'Yes', nan}\n",
            "Growing_Stress : {'No', 'Maybe', 'Yes', nan}\n",
            "Work_Interest : {'No', 'Maybe', 'Yes', nan}\n",
            "Social_Weakness : {'No', 'Maybe', 'Yes', nan}\n",
            "Mood_Swings : {'Medium', 'High', nan, 'Low'}\n",
            "treatment : {'No', 'Yes', nan}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQE1_MNTDKIX"
      },
      "outputs": [],
      "source": [
        "\n",
        "data['Gender']=data['Gender'].map({'Male':0,'Female':1})\n",
        "data['family_history']=data['family_history'].map({'No':0,'Yes':1})\n",
        "data['Occupation']=data['Occupation'].map({'Corporate':1, 'Others':3, 'Housewife':2, 'Student':4, 'Business':0})\n",
        "data['Mental_Health_History']=data['Mental_Health_History'].map({'No':0,'Yes':1,'Maybe':2})\n",
        "data['Growing_Stress']=data['Growing_Stress'].map({'No':0,'Yes':1,'Maybe':2})\n",
        "data['Work_Interest']=data['Work_Interest'].map({'No':0,'Yes':1,'Maybe':2})\n",
        "data['Social_Weakness']=data['Social_Weakness'].map({'No':0,'Yes':1,\"Maybe\":2})\n",
        "data['Mood_Swings']=data['Mood_Swings'].map({'Medium':1, 'High':2, 'Low':0})\n",
        "data['treatment']=data['treatment'].map({'No':0,'Yes':1})\n",
        "\n",
        "#print(data)\n",
        "data = np.array(data)\n",
        "\n",
        "X = data[1:,:-1].astype('int')\n",
        "# print(X[1][0])\n",
        "# print(y)\n",
        "y = data[1:, -1].astype('int')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf2 = RandomForestClassifier(random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "lr = LogisticRegression()\n",
        "stack = StackingClassifier(classifiers=[clf1, clf2, clf3], meta_classifier=lr)\n",
        "stack.fit(X_train, y_train)\n",
        "\n",
        "pickle.dump(stack,open('model.pkl','wb'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "int_features = [1,1,1,1,1,0,1,2]\n",
        "final=[np.array(int_features)]\n",
        "print(int_features)\n",
        "print(final)\n",
        "model=pickle.load(open('model.pkl','rb'))\n",
        "prediction=model.predict_proba(final)\n",
        "output='{0:.{1}f}'.format(prediction[0][1], 2)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEOYamXLNTxT",
        "outputId": "4239e713-60b0-4a20-e275-85c2beb2fe23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 0, 1, 2]\n",
            "[array([1, 1, 1, 1, 1, 0, 1, 2])]\n",
            "0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Input features\n",
        "int_features = [1]*2 + [1]*2 + [1]*4\n",
        "\n",
        "# Reshape input features to a 2D array\n",
        "final = np.array(int_features).reshape(1, -1)\n",
        "\n",
        "# Load the trained model\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "\n",
        "# Make predictions\n",
        "prediction = model.predict_proba(final)\n",
        "\n",
        "# Get the probability of the positive class (index 1)\n",
        "output = '{0:.{1}f}'.format(prediction[0][1], 2)\n",
        "\n",
        "# Print the output\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpN7kl7RJTSi",
        "outputId": "10d70709-0b9a-4c47-85d1-09e255489168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33\n"
          ]
        }
      ]
    }
  ]
}
